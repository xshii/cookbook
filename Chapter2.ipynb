{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.5 Search and replace text - replace(), re.sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yep, but no, but yep, but no, but yep'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple str.replace(a,b)\n",
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "text.replace('yeah', 'yep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is 2012-11-27. PyCon starts 2013-3-13.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re\n",
    "import re\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "datepat.sub(r'\\3-\\1-\\2', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is 27 Nov 2012. PyCon starts 13 Mar 2013.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match_rule.sub(sub_fct,txt)\n",
    "from calendar import month_abbr\n",
    "def change_date(m):\n",
    "\tmon_name = month_abbr[int(m.group(1))]\n",
    "\treturn '{} {} {}'.format(m.group(2), mon_name, m.group(3))\n",
    "datepat.sub(change_date, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Search and replace case-insensitive text - flags=re.IGNORECASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UPPER snake, lower snake, Mixed snake'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'UPPER PYTHON, lower python, Mixed Python'\n",
    "import re\n",
    "re.findall('python', text, flags=re.IGNORECASE)\n",
    "# ['PYTHON', 'python', 'Python']\n",
    "re.sub('python', 'snake', text, flags=re.IGNORECASE)\n",
    "# 'UPPER snake, lower snake, Mixed snake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UPPER SNAKE, lower snake, Mixed Snake'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the most advanced sub rule!\n",
    "def matchcase(word): \n",
    "\tdef replace(m): \n",
    "\t\ttext = m.group() \n",
    "\t\tif text.isupper(): \n",
    "\t\t\treturn word.upper() \n",
    "\t\telif text.islower(): \n",
    "\t\t\treturn word.lower() \n",
    "\t\telif text[0].isupper(): \n",
    "\t\t\treturn word.capitalize() \n",
    "\t\telse: return word \n",
    "\treturn replace\n",
    "\n",
    "re.sub('python', matchcase('snake'), text, flags=re.IGNORECASE)\n",
    "# 'UPPER SNAKE, lower snake, Mixed Snake'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Unicode text to a standard form - unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fully composed\n",
    "s1 = 'Spicy Jalape\\u00f1o'\n",
    "\n",
    "# fully decomposed\n",
    "s2 = 'Spicy Jalapen\\u0303o'\n",
    "s1 == s2\t# False\n",
    "\n",
    "import unicodedata\n",
    "t1 = unicodedata.normalize('NFC', s1)\n",
    "t2 = unicodedata.normalize('NFC', s2)\n",
    "t1 == t2\t# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ﬁ\n",
      "fi\n",
      "fi\n"
     ]
    }
   ],
   "source": [
    "# NFKC NFKD\n",
    "s = '\\ufb01'\t# A single character\n",
    "print(unicodedata.normalize('NFD', s))\n",
    "print(unicodedata.normalize('NFKD', s))\n",
    "print(unicodedata.normalize('NFKC', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spicy Jalapeno'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize\n",
    "t1 = unicodedata.normalize('NFD', s1)\n",
    "''.join(c for c in t1 if not unicodedata.combining(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spicy Jalapeño'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = unicodedata.normalize('NFC', s1)\n",
    "''.join(c for c in t1 if not unicodedata.combining(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.12 Sanitize and clean up text - translate() normalize() 2.9 upper() lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pýthöñ is awesome\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'pýthöñ\\fis\\tawesome\\r\\n'\n",
    "remap = { ord('\\t') : ' ', ord('\\f') : ' ', \n",
    "\t\tord('\\r') : None # Deleted]\n",
    "\t\t}\n",
    "a = s.translate(remap)\t# 'pýthöñ is awesome\\n'\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is awesome\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove combining char\n",
    "import unicodedata\n",
    "import sys\n",
    "cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode)\n",
    "\t\t\t\t\t\tif unicodedata.combining(chr(c)))\n",
    "b = unicodedata.normalize('NFD', a)\n",
    "b.translate(cmb_chrs)\t# 'python is awesome\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arabic to ASCII\n",
    "digitmap = { c: ord('0') + unicodedata.digit(chr(c))\n",
    "\t\tfor c in range(sys.maxunicode)\n",
    "\t\tif unicodedata.category(chr(c)) == 'Nd' }\n",
    "x = '\\u0661\\u0662\\u0663'\n",
    "x.translate(digitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is awesome\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple way\n",
    "b = unicodedata.normalize('NFD', a)\n",
    "b.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'Is Chicago'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.14 Combine and concatenate strings - join() + '{} {}'.format(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Chicago Not Chicago?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample():\n",
    "    yield 'Is'\n",
    "    yield 'Chicago'\n",
    "    yield 'Not'\n",
    "    yield 'Chicago?'\n",
    "    \n",
    "text = ' '.join(sample())\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(source,maxlen):\n",
    "    parts = []\n",
    "    size = 0\n",
    "    for part in source:\n",
    "        parts += part\n",
    "        size += len(part)\n",
    "        if size > maxlen:\n",
    "            yield ' '.join(parts)\n",
    "            parts = []\n",
    "            size = 0\n",
    "    yield ' '.join(parts)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.15 Set Vars in strings - str.format(attr=value) format_map(vars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has 37 messages.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normal case\n",
    "s = '{name} has {n} messages.'\n",
    "s.format(name='Guido', n=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has 37 messages.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use format_map(vars())\n",
    "name = 'Guido'\n",
    "n = 37\n",
    "s.format_map(vars())\n",
    "# 'Guido has 37 messages.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has 37 messages.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use format_map(vars(class_obj))\n",
    "class Info:\n",
    "\tdef __init__(self, name, n):\n",
    "\t\tself.name = name\n",
    "\t\tself.n = n\n",
    "a = Info('Guido',37)\n",
    "s.format_map(vars(a))\n",
    "# 'Guido has 37 messages.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has {n} messages.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aware of missing variables\n",
    "class safesub(dict):\n",
    "    def __missing__(self, key):\n",
    "        return '{' + key + '}'\n",
    "del n \t# delete n n can be only deleted once\n",
    "s.format_map(safesub(vars()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def sub(text):\n",
    "    return text.format_map(safesub(sys._getframe(1).f_locals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame hack\n",
    "import sys\n",
    "def sub(text):\n",
    "\treturn text.format_map(safesub(sys._getframe(1).f_locals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.16 Reformat text to a fixed number of columns - textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\\n",
    "the eyes, not around the eyes, don't look around the eyes, \\\n",
    "look into my eyes, you're under.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look into my eyes, look into my eyes,\n",
      "the eyes, the eyes, the eyes, not around\n",
      "the eyes, don't look around the eyes,\n",
      "look into my eyes, you're under.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "print(textwrap.fill(s,40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.get_terminal_size().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.18 Tokenize text - re, r'(?P<TOKENNAME>match_rule)', scanner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='foo'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)' \n",
    "NUM = r'(?P<NUM>\\d+)' \n",
    "PLUS = r'(?P<PLUS>\\+)' \n",
    "TIMES = r'(?P<TIMES>\\*)' \n",
    "EQ = r'(?P<EQ>=)' \n",
    "WS = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))\n",
    "scanner = master_pat.scanner('foo = 42')\n",
    "scanner.match() # <_sre.SRE_Match object at 0x100677738>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NAME', 'foo')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.lastgroup,_.group() #('NAME', 'foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Token = namedtuple('Token',['type','value'])\n",
    "\n",
    "def generate_tokens(pat,text):\n",
    "\tscanner = pat.scanner(text)\n",
    "\tfor i in iter(scanner.match,None):\n",
    "\t\tyield Token(i.lastgroup, i.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(type='NAME', value='foo'),\n",
       " Token(type='WS', value=' '),\n",
       " Token(type='EQ', value='='),\n",
       " Token(type='WS', value=' '),\n",
       " Token(type='NUM', value='42')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(generate_tokens(master_pat, 'foo = 42'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.19 Write a recursive descent parser - one rule one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "# Token specification \n",
    "NUM \t= r'(?P<NUM>\\d+)' \n",
    "PLUS \t= r'(?P<PLUS>\\+)' \n",
    "MINUS\t= r'(?P<MINUS>-)' \n",
    "TIMES\t= r'(?P<TIMES>\\*)' \n",
    "DIVIDE\t= r'(?P<DIVIDE>/)'\n",
    "LPAREN\t= r'(?P<LPAREN>\\()' \n",
    "RPAREN\t= r'(?P<RPAREN>\\))' \n",
    "WS\t= r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NUM, PLUS, \n",
    "\t\tMINUS, TIMES, DIVIDE, LPAREN, RPAREN, WS]))\n",
    "\n",
    "# Tokenizer \n",
    "Token = collections.namedtuple('Token', ['type','value'])\n",
    "\n",
    "def generate_tokens(text):\n",
    "    scanner = master_pat.scanner(text)\n",
    "    for i in  iter(scanner.match,None): # must be like this!\n",
    "        tok = Token(i.lastgroup, i.group())\n",
    "        if tok.type != 'WS':\n",
    "            yield tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionEvaluator:\n",
    "    def parse(self,text):\n",
    "        self.tokens = generate_tokens(text)#2.18\n",
    "        self.tok = None\t#last symbol consumed\n",
    "        self.nexttok = None # next symbol tokenized\n",
    "        self._advance()\t#load first lookahead token\n",
    "        return self.expr()\n",
    "    \n",
    "    def _advance(self):\n",
    "        'Advance one token ahead'\n",
    "        self.tok, self.nexttok = self.nexttok,next(self.tokens, None)\n",
    "        \n",
    "    def _accept(self,toktype):\n",
    "        'test and consume the next token if matches'\n",
    "        if self.nexttok and self.nexttok.type == toktype:\n",
    "            self._advance()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def _expect(self,toktype):\n",
    "        if not self._accept(toktype):\n",
    "            raise SyntaxError('Expected '+toktype)\n",
    "\n",
    "    # gramma rules\n",
    "    def expr(self):\n",
    "        '''expression ::= term {('+'|'-') term}'''\n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval += right\n",
    "            elif op == 'MINUS':\n",
    "                exprval -= right\n",
    "        return exprval\n",
    "    \n",
    "    def term(self):\n",
    "        '''term ::= factor {('*'|'/') factor}'''\n",
    "\n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'TIMES':\n",
    "                termval *= right\n",
    "            elif op == 'DIVIDE':\n",
    "                termval /= right\n",
    "        return termval\n",
    "\n",
    "    def factor(self):\n",
    "        'factor ::= NUM | (expr)'\n",
    "\n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPAREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER or LPAREN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "e = ExpressionEvaluator()\n",
    "print(e.parse('2*(2+2)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.20 Operations on byte strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Hello', b'World']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match pattern\n",
    "data = b'Hello World'\n",
    "data.startswith(b'Hello')\n",
    "import re\n",
    "re.split(b'[\\s]',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
